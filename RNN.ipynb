{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.callbacks import Callback\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('GOOGL_2006-01-01_to_2018-01-01.csv', parse_dates=['Date'])\n",
    "\n",
    "data = data.drop(\"Name\", axis=1)\n",
    "data.set_index('Date', inplace=True)\n",
    "\n",
    "\n",
    "# Ensure data has business day frequency\n",
    "data = data.asfreq('b')\n",
    "\n",
    "# Fill missing values\n",
    "data = data.fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "\n",
    "\n",
    "#Normalize\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "train_end_idx = int(data.shape[0] * train_ratio)\n",
    "val_end_idx = int(data.shape[0] * (train_ratio + val_ratio))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data.iloc[:train_end_idx] = scaler.fit_transform(data.iloc[:train_end_idx])\n",
    "data.iloc[train_end_idx:] = scaler.transform(data.iloc[train_end_idx:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Normalize the data (apply MinMaxScaler across all features)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "data_normalized = scaler.fit_transform(data)\n",
    "\n",
    "# Define sequence length\n",
    "sequence_length = 100\n",
    "\n",
    "# Prepare input (X) and output (Y) sequences\n",
    "X, Y = [], []\n",
    "for i in range(len(data_normalized) - sequence_length):\n",
    "    X.append(data_normalized[i:i + sequence_length])  # Input: sequence_length x num_features\n",
    "    Y.append(data_normalized[i + sequence_length])    # Output: num_features\n",
    "\n",
    "X = np.array(X)  # Shape: (samples, sequence_length, num_features)\n",
    "Y = np.array(Y)  # Shape: (samples, num_features)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(split_ratio * len(X))\n",
    "X_train, X_test = X[:split_index], X[split_index:]\n",
    "Y_train, Y_test = Y[:split_index], Y[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model for multivariate input/output\n",
    "model = Sequential([\n",
    "    SimpleRNN(units=80, input_shape=(sequence_length, X.shape[2])),  # Sequence length and features\n",
    "    Dense(units=Y.shape[1])  # Number of output features\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train, epochs=20, batch_size=20, verbose=1)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Inverse scale predictions and actual values for evaluation\n",
    "predictions_rescaled = scaler.inverse_transform(predictions)\n",
    "Y_test_rescaled = scaler.inverse_transform(Y_test)\n",
    "\n",
    "# Evaluate the model using Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(Y_test_rescaled, predictions_rescaled)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# Optional: Visualize some predictions vs actuals\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(Y_test_rescaled[:100, 0], label='Actual (First Feature)')\n",
    "plt.plot(predictions_rescaled[:100, 0], label='Predicted (First Feature)')\n",
    "plt.legend()\n",
    "plt.title(\"Actual vs Predicted (First Feature)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize prediction_X with the last sequence from the dataset\n",
    "prediction_X = X[0]  # Ensure this is a sequence of shape (sequence_length, num_features)\n",
    "\n",
    "# Number of steps to forecast\n",
    "steps = 100\n",
    "\n",
    "# Store forecasts\n",
    "forecasts = []\n",
    "\n",
    "for i in range(steps):\n",
    "    # Reshape prediction_X to include batch dimension\n",
    "    prediction_X_batch = prediction_X.reshape((1, prediction_X.shape[0], prediction_X.shape[1]))\n",
    "\n",
    "    # Predict the next step\n",
    "    forecast_new = model.predict(prediction_X_batch)\n",
    "\n",
    "    # Add the prediction to forecasts\n",
    "    forecasts.append(forecast_new[0])  # Remove batch dimension from prediction\n",
    "\n",
    "    # Update prediction_X: Remove the first value and append the new prediction\n",
    "    prediction_X = np.vstack([prediction_X[1:], forecast_new])\n",
    "\n",
    "# Convert forecasts to a NumPy array for further processing\n",
    "forecasts = np.array(forecasts)\n",
    "\n",
    "# Inverse transform the forecasts if needed (to return to original scale)\n",
    "forecasts_rescaled = scaler.inverse_transform(forecasts)\n",
    "print(\"Forecasts (original scale):\")\n",
    "print(forecasts_rescaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(Y_test_rescaled[:100, i], label='Actual (First Feature)')\n",
    "    plt.plot(forecasts_rescaled[:100,i], label='Forecast (First Feature)')\n",
    "    plt.legend()\n",
    "    plt.title(\"Actual vs Forecast (First Feature)\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kernel Python 1",
   "language": "python",
   "name": "nome_tuo_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
